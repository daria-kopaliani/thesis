\documentclass{vakthesis}
\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\newcommand{\SweaveOpts}[1]{}  % do not interfere with LaTeX
\newcommand{\SweaveInput}[1]{} % because they are not real TeX commands
\newcommand{\Sexpr}[1]{}       % will only be parsed by R


\usepackage[T2A]{fontenc}
\usepackage[cp1251]{inputenc}
\usepackage[english,russian,ukrainian]{babel}
\usepackage{geometry}
\usepackage{mathtools}% http://ctan.org/pkg/mathtools
\usepackage{amsmath}
\usepackage[numbers,sort&compress]{natbib}
\usepackage{color,soul}
\usepackage{graphicx}
\usepackage{MnSymbol}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{float}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage[labelsep=endash]{caption}
\usepackage[shortcuts]{extdash}

\graphicspath{{images/}}


%\geometry{hmargin={30mm,15mm},lines=29,vcentering}
\everymath=\expandafter{\the\everymath\displaystyle}

\geometry{a4paper, total={170mm,257mm}, left=25mm, top=20mm}

%This is to make proper table captions, you most definately do *not* want to edit this
\makeatletter
\let\ORG@makecaption\@makecaption
\let\ORGlongtable\longtable
\let\ORGLT@makecaption\LT@makecaption
\AtBeginDocument{%
  \let\@maketablecaption\ORG@makecaption
  \let\longtable\ORGlongtable
  \let\LT@makecaption\ORGLT@makecaption
}
\makeatother


%\DeclareMathSizes{10}{10}{10}{10}


\begin{document}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\color{warningcolor}{\#\# Warning in grepl(db, input): input string 43 is invalid in this locale}}

{\ttfamily\noindent\color{warningcolor}{\#\# Warning in grepl(db, input): input string 44 is invalid in this locale}}

{\ttfamily\noindent\color{warningcolor}{\#\# Warning in grepl(db, input): input string 45 is invalid in this locale}}

{\ttfamily\noindent\color{warningcolor}{\#\# Warning in grepl(db, input): input string 48 is invalid in this locale}}

{\ttfamily\noindent\color{warningcolor}{\#\# Warning in grepl(db, input): input string 53 is invalid in this locale}}

{\ttfamily\noindent\color{warningcolor}{\#\# Warning in grep("{}\textasciicircum{}\textbackslash{}\textbackslash{}\textbackslash{}\textbackslash{}bibliography.+"{}, input, value = TRUE): input string 43 is invalid in this locale}}

{\ttfamily\noindent\color{warningcolor}{\#\# Warning in grep("{}\textasciicircum{}\textbackslash{}\textbackslash{}\textbackslash{}\textbackslash{}bibliography.+"{}, input, value = TRUE): input string 44 is invalid in this locale}}

{\ttfamily\noindent\color{warningcolor}{\#\# Warning in grep("{}\textasciicircum{}\textbackslash{}\textbackslash{}\textbackslash{}\textbackslash{}bibliography.+"{}, input, value = TRUE): input string 45 is invalid in this locale}}

{\ttfamily\noindent\color{warningcolor}{\#\# Warning in grep("{}\textasciicircum{}\textbackslash{}\textbackslash{}\textbackslash{}\textbackslash{}bibliography.+"{}, input, value = TRUE): input string 48 is invalid in this locale}}

{\ttfamily\noindent\color{warningcolor}{\#\# Warning in grep("{}\textasciicircum{}\textbackslash{}\textbackslash{}\textbackslash{}\textbackslash{}bibliography.+"{}, input, value = TRUE): input string 53 is invalid in this locale}}\end{kframe}
\end{knitrout}
\chapter{Огляд стану проблеми та постановка задачі дослідження}
\label{ch:ProbleAnalysis} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Навчання та самонавчання штучних нейронних мереж}

Здатність навчатися – основна властивість біологічного мозку, а оскільки штучна нейронна мережа в деякому сенсі моделює мозок, поняття <<навчання>> посідає щонайперше місце в теорії штучних нейронних мереж. Математичні проблеми, що пов’язані з навчанням, вивчають у напрямі загальної теорії штучних нейронних мереж, який дістав назву <<нейроматематика>> \hl{[51, 52]}. Із точки зору нейроматематики, навчання тлумачать як завдання адаптувати параметри, а можливо, й архітектуру мережі, щоби, оптимізуючи прийнятий критерій якості, розв’язати поставлену задачу. Таке визначення є узвичаєним та неявно припускає, що нейроматематика ґрунтується на методах оптимізації та ідентифікації.

Звичайно припускають, що навчання має перманентний характер та з часом мережа покращує свої характеристики, постійно <<наближаючись>> до оптимального розв’язку поставленої задачі.

Тип та характер навчання обумовлені, насамперед, обсягом попередньої та поточної інформації про довкілля, в яке <<занурили>> мережу, а також критерієм якості (цільовою функцією), що характеризує рівень відповідності нейронної мережі до розв’язуваної нею задачі. Інформацію про довкілля здебільшого задають у вигляді навчальної вибірки образів або зразків, що їх оброблюючи мережа дістає відомості, необхідні для отримання шуканого розв’язку. Саме характер та обсяг цієї інформації визначають як тип навчання, так і конкретний метод.

З погляду математики, навчання нейронних мереж – це багатопараметрична задача нелінійного оптимування. Більшість методів навчання можна розділити на два класи: навчання з учителем (із заохоченням) та навчання без учителя (без заохочення, або самонавчання). Методи навчання з учителем застосовують у випадках, коли відома бажана реакція системи в кожну мить часу, себто відомий навчальний сигнал, який упливає на налаштування параметрів системи, що навчається. Рівень <<навченості>> системи формально визначають за значенням цільової функції, тобто за тим станом, якого має в результаті набути коректно навчена система.

Парадигму навчання <<з учителем>> схематично представлено на рис.~\ref{fig:SupervisedLearning}

\begin{figure}[h]
\begin{center}
\includegraphics{SupervisedLearning.png}
\caption{Схема навчання з учителем}
\label{fig:SupervisedLearning}
\end{center}
\end{figure}

У цій схемі <<учителю>> відома інформація про довкілля, представлена послідовністю або пакетом ухідних векторів $x$, а також <<правильна реакція>> на ці сигнали, позначена навчальним сигналом $\hat{y}$. В процесі навчання реакція нейронної мережі y розбігається з <<правильною>> реакцією вчителя, через що постає похибка $e = \hat{y} = y$. Мета навчання – так налаштувати параметри штучної нейронної мережі, щоби деяка скалярна функція похибки $E\left(e\right)$ (критерій якості) досягла свого найменшого значення. Навченою вважають мережу, яка в деякому, переважно статистичному сенсі повторює реакцію вчителя. Позаяк інформація про довкілля здебільшого має нестаціонарний характер, навчання відбувається безперервно, для чого використовують ті чи інші рекурентні процедури.

Альтернатива навчанню <<з учителем>> – навчання за умов, коли правильна реакція на сигнали довкілля невідома. Цю парадигму називають навчанням <<без учителя>>, або самонавчанням. Штучні нейронні мережі, що самонавчаються, здебільшого, призначені аналізувати внутрішню латентну структуру вхідної інформації та розв’язують задачі автоматичного класифікування, кластерування, факторного аналізу, компресування даних тощо. У теорії штучних нейронних мереж самонавчання звичайно розглядають як конкурування або самоорганізування нейронів мережі, що топологічно взаємозв’язані між собою.

Самонавчання схематично представлено на рис. \ref{fig:UnsupervisedLearning}.

\begin{figure}[h]
\begin{center}
\includegraphics{UnsupervisedLearning.png}
\caption{Схема самонавчання}
\label{fig:UnsupervisedLearning}
\end{center}
\end{figure}

Аби покращити якість навчання та прискорити збіжність, ітераційне навчання можна повторювати циклічно на так званому <<вікні>> – наборі послідовних значень навчального сигналу (у дискретному випадку) або проміжкові часу (у неперервному випадку). Граничним варіантом процедур з повторюванням є пакетне та послідовне (у реальному часі) модифікування. Під пакетним режимом розуміють випадок, коли всю вибірку даних задано попередньо, а навчання відбувається <<епохами>>. У режимі реального часу повторювання відсутнє, хоча якщо зорганізувати навчання в <<прискореному>> машинному часі, навчання може повторюватися. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Задача нечіткого кластерування даних}

Нечітке кластерування даних – один з напрямів кластерного аналізу, що використовує для обробляння даних деякі принципи та елементи нечіткої логіки [77, 78]. Концептуальний взаємозв’язок між кластерним аналізом та нечіткою логікою ґрунтується на тій обставині, що розв’язання задач структурування складних систем формує здебільшого кластери об’єктів, що є розмиті, нечіткі за своєю природою. Така нечіткість може полягати в тому, що перехід від належності до неналежності образів щодо певних кластерів радше поступовий, аніж стрибкуватий. Тому адекватнішою в таких випадках є не однозначна належність до певного кластеру, а низка рівнів належності до кількох кластерів. Вимога однозначно розкластерувати елементи досліджуваної проблемної області є вельми грубою та жорсткою, особливо у випадках, коли треба розв’язати погано або слабко структуровані задачі інтелектуального аналізу даних. Засоби нечіткого кластерування послаблюють цю вимогу введенням до розгляду нечітких кластерів та їхніх функцій належності, які приймають значення на інтервалі $\left[0, 1\right]$.

З-поміж цілої низки методів та підходів нечіткого кластерування особливе місце займають методи, що ґрунтуються на цільових функціях [79]. Такі методи розв’язують задачу обробляння даних, оптимуючи деякий заздалегідь заданий критерій якості. Найвідомішим представником цього класу методів є метод нечітких с-середніх [77], що його широко застосовують у задачах різноманітної складності, коли навчальний сигнал невідомий. Але хоча стандартний метод нечітких с-середніх є значно просунутішим порівняно з методами чіткого кластерування, але все ж таки й він має вади. Справа в тому, що однією
з умов використовування цього методу є вимога, щоби сума рівнів належності будь-якого образа за всіма кластерами дорівнювала одиниці. Ця штучна вимога
у випадках рівновіддаленості деякого образа від усіх кластерів спричиняє те, що такий образ отримує рівень належності до кожного з кластерів, який не залежить од відстані між образом та центром відповідного кластеру. Іще однією вадою методу, яка випливає з попередньої, є припущення, що під час обробляння даних образи, що належать новим кластерам, з’явитися не можуть. Вочевидь, в реалістичних задачах це не завжди так. До того ж образи, що надходять на вхід методу, можуть бути звичайним шумом, завадами. Стандартний метод нечітких с-середніх не впорається з такою ситуацією, що відповідно позначиться на ефективності кінцевого нечіткого розбиття даних.

Зазначену ваду долає метод можливісного нечіткого кластерування даних – метод можливісних с-середніх [77, 80, 81]. Він не має вимог щодо значення суми рівнів належності образів за всіма кластерами, що, відповідно, покращує його дієвість за умов наявності шуму в ухідному сигналі. Проте цей метод має певні труднощі з його початковим ініціалізуванням.

Беручи до уваги те, що обидва розглянуті методи належать до методів нечіткого кластерування даних, тут годилося б зазначити, що коли виникає потреба виокремити стандартний метод нечітких с-середніх, його називають імовірнісним.

Два розглянуті методи нечіткого кластерування даних – імовірнісний та можливісний – є базові методи, які утворюють цілі сім’ї похідних від них і пристосованих до певних специфічних задач обробляння даних [77]. Зазвичай, кожен зі згаданих методів обробляє дані в пакетному режимі. У ситуаціях, коли дані надходять окремо й їх потрібно обробляти он-лайн, для методів нечіткого кластерування запропоновано послідовні модифікації [77, 82].

Іще одна вада стандартних методів нечіткого кластерування даних – нездатність виявляти кластери складної, несферичної форми. Цю ваду, опріч уже згаданого ієрархічного кластерування, долає метод нечіткого кластерування Ґустафсона-Кесселя, який, замість Евклідової, використовує Магаланобісову метрику [83].

Як видно, існує розмаїття методів нечіткого кластерування, зоснованих на оптимуванні цільової функції. Але усі вони ґрунтуються на припущенні, що дослідникові попередньо відома кількість кластерів, що їх треба виявити. Допевне, таке припущення слушне не для всіх задач, адже інколи кількість кластерів у вхідних даних може бути невідомою або вона може змінюватися в часі. Цей випадок є предметом розгляду систем обробляння даних із мінливою (еволюційною) архітектурою [84], які здебільшого є гібридними системами з поліпшеними архітектурами, що поєднують декілька напрямків обчислювального інтелекту.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Гібридні системи обчислювального інтелекту}

В обчислювальному інтелекті вельми поширеним є підхід створювати систем обробляння даних на основі кількох наукових напрямів. Як засвідчують теоретичні та практичні результати, таким гібридним системам властивий синергетичний ефект, тобто вони виявляють такі властивості, яких не мають системи, що їх утворюють~\hl{[85]}.
Одним з яскравих прикладів гібридних систем обчислювального інтелекту є нейро-фазі системи, які поєднують у собі нейронні мережі другого покоління та нечіткі системи~\hl{[9, 85]}. Нейронна мережа може навчатися на вхідних та вихідних даних для визначення поведінки системи, але отримані знання будуть сховані в її синапсових вагах і їх не можна буде витлумачити. Однак, якщо виразити ваги нейронної мережі за допомогою нечітких правил, з’являється можливість подолати неінтерпретовність результатів роботи нейронної мережі. У такий спосіб нейрофаззі системи дають змогу створювати системи обробляння інформації та отримують більш шіроке застосування.
Розвиваючи гібридний підхід, запропоновано й просунутіші поєднання наукових напрямків, наприклад, теорії штучних нейронних мереж та індуктивного моделювання даних~\hl{[86]}. Ефективність кластерування даних залежить у великій мірі від якості обраної математичної моделі розв’язуваної або досліджуваної задачі. Як уже мовилося вище, однією з проблем кластерування даних є змінна кількість кластерів оброблюваних даних. Відповідно постає складна задача обрати належну математичну модель. Індуктивне моделювання має тут ефективний розв’язок: налаштовувати не лише параметри системи обробляння даних, але також і її структуру. Проекція такого підходу на штучні нейронні мережі веде до ідеї змінювати кількість нейронів в шарах мережі, що обробляє дані. Дієвість роботи побудованих за цим принципом систем~\hl{[87, 88]} засвідчує плідність гібридного підходу.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section {Гібрідні нейро-фаззі системи та питанная структурної адаптації}

В наш час для розв'язання задач, які пов'язані з інтелектуальною обробкою даних в умовах апріорної та поточної невизначеності, дослідники часто не обмежуються використанням якогось одного підходу (нейронні мережі, нечітка логіка, генетичні алгоритми тощо), а задля синергії зв'язують групу методів в одну гібридну систему~\cite{ref86, ref87} . Такі системи відповідають усім вимогам до інтелектуальних систем і отримали назву гібридні системи обчислювального інтелекту. Нейро-фаззі системи та м'які обчислювання є напрямами дисципліни обчислювального інтелекту, які й займаються проблемами таких систем. 
Серед основних характеристик систем, шо розробляються в рамках нейро-фаззі систем та м'яких обчислень, можна виділити наступні \hl{[27]}:

\begin{itemize}
\item обислювальні моделі, що засновані на біологічних прототипах,
\item паралельна обробка даних у послідовному режимі,
\item в основі системи лежать експертні знання,
\item стійкість системи до зашумленості,
\item стійкість системи до виходу із строю підсистем.
\end{itemize}

Варто зазначити, що однією із головних умов до такого типу систем, є їх орієнтованість на розв'язання практичних завдань, що означає здатність оброблювати великі масиви даних великої розмірності, які можуть мати пропущені та зашумленні значення. Однак навчання таких систем зводиться до налаштування синаптичних коефіцієнтів та/або адаптації бази нечітких правил. Тобто архітектура такої системи не зазнає жодних змін, що може в деяких випадках призвести до погіршення точності результатів. В зв'язку з цим видаюється очевидно корисним зсинтезувати таку гібридну нейро-фаззі архітектуру та такі алгоритми її навчання, що здатні змінювати не тільки параметри системи, а й її архітектуру.

Як вже зазначалось, основною метою навчання є отримання нейронної мережі, яка здатна у найкращий спосіб відтворювати попередньо невідоме відображення $R^{n} \rightarrow R^{m}$. В якості такого відображення може виступати залежність вихідних параметрів процесу від вхідних, прогнозування від передісторії, класу об'єкту від набору його властивостей, управляючої дії від поточного стану об'єкта тощо. Коректне налаштування не тільки синаптичних коефіцієнтів, а й архітектури нейронної мережі, зокрема налаштування кількості шарів та кількості нейронів у кожному шарі, дозволяю суттєво покращити показники такої мережі. Серед підходів до налаштування архітектури нейронної мережі виділяють:
\begin{itemize}
\item деструктивний підхід: за основу береться заздалегідь надлишкова модель, до неї застосовуються різні процедури, що видаляють із початкової мережі елементи, які надають негативниий або незначний позитивний ефект на кінцевий результат,
\item конструктивний підхід: за основу береться максимально проста модель (складається із одного або декількох нейронів), до неї застосовуються процедури, що додають початковій мережі нові елементи до певного моменту, в залежності від методу, що використовується. Як варіант, конструктивний алгоритм може стартувати з цілком нульової архітектури та самостійно генерувати шари мережі в процесі своєї роботи.
\end{itemize}

\subsection {Деструктивний підхід до налаштування архітектури нейронної мережі}

Основна ідея деструктивних алгоритмів полягає у видаленні параметрів, що мають найменший вплив на вихідний сигнал мережі. У ряді публікацій \hl{30-32} було сформульовано та підтвержено припущення, що використання деструктивних алгоритмів нерідко призводить до покращення узагальнюючих властивостей мережі, допомагає нейтралізувати появу так званого ефекту перенавчання, а, крім того, після закінчення роботи такого алгоритму, архітектура мережі набуває меншого та простішого вигляду, що, вочевидь, позитвино відбивається на її обчислювальній складності.

У процесі функціонування деструктивних алгоритмів із мережі можуть бути цілком видалені як деякі вхідні параметри або вузли у прихованих шарах, так і лише деякі синаптичні зв'язки між нейронами, що мають лише один параметр -- ваговий коефіцієнт. В основі деструктивного піходу до структурної адаптаціі нейронної мережі має бути закладено обчислення певної міри значущості, яка буде характеризувати ступінь впливу кожного конкретного параметру на вихідний сигнал.

В одній із перших публікацій, що розглядає цю проблему~\hl{[30]}, автори запропонували деструктивний алгоритм структурної оптимізації під назвою Optimal Brain Damage (OBD), яки х складається із наступних етапів:
\begin{enumerate}
\item обрати архітектуру нейронної мережі,
\item використовуючи один із методів мінімізації цільової функції якості, провести навчання мережі,
\item для кожного елементу мережі обчислити міру значущості за формулою:

\begin{equation}\label{eq:obd}
s_{q}=h_{q}u_{q}^2/2,
\end{equation}
\medskip

де $u_{q}$ -- вихідний сигнал $q$-го елементу мережі,\\
$h_q$ розраховується по формулі:

\begin{equation}\label{eq:h_q}
h_q=\sum\limits_{\left(i,j\right)\in V_q}\frac{\partial^{2}{E}}{\partial{w_{ij}^{2}}},
\end{equation}
\medskip

де $V_q$ -- множина пар коефіцієнтів $i$ та $j$ для $q$-го елемента мережі, 

E -- помилка на виході нейронної мережі, 

$w_{ij}$ -- синаптичний ваговий коефіцієнт в $j$-м шарі,

\item видалити із мережі деяку кількість елементів, для яких міра значущості $s_q$ найменша. У цьому контексті під видаленням елементу мається на увазі зміна вихідного значення елемента на 0 та замороження його в такому стані,
\item повернутися на крок 2 та повторити процедуру.
\end{enumerate}

Варто зазначити, що при використанні такого методу значно збільшується обчислювальна складність методу навчання, і через необхідність розрахувати міру значущості для кожного нейрону, і через додаткові ітерації перенавчання, які необхідно виконати після видалення кожного нейрона із мережі. Також суттєвим недоліком є те, що разом з видаленням нейрона ми видаляємо відразу декілька синаптичних зв'язків, хоча деякі із них можуть бути корисними. У \hl{[31]} було запропановано спосіб обійти цей недолік, а разом із тим збільшити швидкість процесу навчання. Цей підхід отримав назву Optimal Brain Surgeon~(OBS), і складається він із наступних етапів:

\begin{enumerate}
\item вибрати мережу із достатньо надлишковою архітектурою та провести її навчання,
\item обчислити $H^{-1}$ - матрицю, зворотню до гессіану: $H = \frac{\partial^{2}{E}}{\partial{w^{2}}}$,
\item обчислити міру значущості для кожного елементу:

\begin{equation}\label{eq:L_q}
L_q=w_{q}^{2}/\left(2[H^{-1}]_{qq}\right),
\end{equation}
\medskip

де $w_q$ -- $q$-ий ваговий коефіцієнт в мережі,

\item якщо мінімальний $S_q$ значно менший за поточну помилку, то $w_q$ має бути видалений, після чого перейти до кроку номер 5, в іншому разі перейти до кроку номер 6,
\item оновити вектор вагових коефіцієнтів мережі, використовуючи наступний вираз:

\begin{equation}\label{eq:delta_w}
\delta{W}=-\frac{w_q}{[H^{-1}]_{qq}}H^{-1}\zeta_{q},
\end{equation}
\medskip

де $\zeta_{q}$ -- орт-вектор у площині вагових коефіцієнтів мережі, який відповідає $q$-й синаптичній вазі,

\item усі незначущі вагові коефіцієнти видаляються, після чого бажано перенавчити мережу.
\end{enumerate}

Слід зауважити, що перший же крок цього методу, а саме вибір критерію надмірності архітектури, може викликати багато запитань. В цілому ж, запропонований в \hl{[31]} метод також характеризується значною обчислювальною складністю, хоч і меншою, в порівнянні з OBD, оскільки він не потребує перенавчання всієї мережі після видалення кожного вагового коефіцієнта. Але методам, що описані вище, притаманний ще один істотний недолік -- необхідність мати вже навчену нейронну мережу до початку роботи алгоритму. Це обмеження вдалося обійти завдяки методу, що був запропонований у \hl{[36]}, де міра значущості для вагових коефіцієнтів визначається через тестову статистику~$T$, спираючись на те, що ваговий коефіцієнт обнуляється у процесі навчання мережі:

\begin{equation}\label{eq:T_w}
T_{(w_q)}=\log\left(\frac{\left|\sum\limits_{k=1}^{N}\left(w_q-\eta{\left(\frac{\partial{E}}{\partial{w_q}}\right)}_k\right)\right|}{\eta\sqrt{\sum\limits_{k=1}^{N}{\left({\left(\frac{\partial{E}}{\partial{w_q}}\right)}_k-\left(\frac{\partial{E}}{\partial{w_q}}\right)\right)}^2}}\right),
\end{equation}
\medskip

де $N$ -- кількість прикладів у виборці.

У рамках деструктивного підходу відомі також і багато інших методів оптимізації архітектури нейронної мережі \hl{[33-35,37-39]}, проте в силу специфіки цього підходу всім їм в тій чи іншій мірі властива додаткова обчислювальна складність, а також орієнтація на нейронні мережі з архітектурою типу багатошарового персептрону. Використання таких алгоритмів для налаштування інших архітектур, зокрема для нейро-фаззі систем, неможливо, а розробка видається недоцільною, оскільки в будь-якому разі використання деструктивного алгоритму матиме прямий негативний вплив як на час навчання, так і на час функціонування мережі. Для систем, що розробляються в рамках напряму нейро-фаззі і м'яких обчисленнь, час є досить критичним параметром, оскільки ці системи орієнтуються на рішення практичних задач. У зв'язку з цим вельми привабливо виглядає використання конструктивного підходу для синтезу архітектури нейронної мережі, про що йтиметься далі.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Конструктивний підхід до налаштування архітектури нейронної мережі}

Суть конструктивного підходу полягає в нарощуванні архітектури нейронної мережі і налаштування її вагових коефіцієнтів паралельно, доки не будуть задоволені вимоги критерію зупинки. Тобто цей підхід дозволяє не тільки уникнути перенавчання нейронної мережі, а й оптимізує структуру й архітектуру мережі на етапі навчання.

Таким чином, використовуючи конструктивний підхід, можна повністю вирішити питання про вибір початкової архітектури мережі: в загальному випадку вона повинна бути максимально простою, складатися з одного або декількох нейронів (залежить від методу). Слід зауважити, що, як правило, в результаті роботи конкретного конструктивного алгоритму на виході отрумуємо нейронну мережу нетрадиційної архітектури.

В \hl{[40]} Джон Платт описує нейронну мережу, що дістала назву Resource-Allocating Network~(RAN), яка в процесі навчання додає в свою архітектуру нові обчислювальні елементи (штучні нейрони) кожен раз, коли до входу мережі подається новий навчальний приклад, який в RAN має двошарову архітектуру. Перший шар складається з нейронів, що відповідають за локальну область з простору вхідних сигналів. У випадку, коли вхідний сигнал віддаляється від області конкретного нейрона, то значення сигналу на його виході зменшуватиметься відповідно співвідношенню:

\begin{equation} \label{eq:x_j}
\begin{cases}
x_j=
\begin{cases}
{\left(1-\left(\frac{z_j}{\chi{w^{2}_j}}\right)\right)}^2,\text{ якщо } z_j<\chi{w_j}^2 \\
0,\text{      у протилежному випадку}
\end{cases} \\
z_j=\sum\limits_{j}{\left(c_{ij}-X_i\right)}^2,
\end{cases}
\end{equation}
\medskip

де $X_i$ -- $i$-ий вхід нейронної мережі,

$c_{ij}$ -- $i$-ий ваговий коефіцієнт $j$-го нейрона першого шару,

$\chi$ -- параметр налаштування, який підбирається емпіричним шляхом.

Виходи першого шару $x_j$ подаються на другий шар, який агрегує ці значення і генерує вихідний сигнал. Метою кожного синапсу другого шару є визначити, який вплив надає кожен нейрон першого шару на формування конкретного цільового вектора $\vec{y}$. Вихідним сигналом мережі $\vec{y}$ є зважена сума виходів першого шару плюс незалежний вектор $\vec{\gamma}$, що містить постійні елементи:

\begin{equation}\label{eq:vec_y}
\vec{y}=\sum\limits_{j}\vec{w}^{[\circ]}x_j+\vec{\gamma},
\end{equation}
\medskip

де $\vec{w}^{[\circ]}$---вектор синаптичних ваг вихідного шару, або в скалярній формі:

\begin{equation}
y_i=\sum\limits_{j}w^{[\circ]}_{ji}x_j+{\gamma}.
\end{equation}
\medskip

Також $\vec{\gamma}$ є виходом нейронної мережі у випадку, якщо не активувався жоден з нейронів першого шару. У певному сенсі вираз ${\vec{w_j}^{[\circ]}x_j}$ може розглядатися як певний адитивний елемент, який може бути використаний для того, щоб отримати бажаний вихідний сигнал. 
Навчання RAN починається з нульового стану, тобто в першому шарі не міститься жодного нейрона, а в другому кількість нейронів дорівнює розмірності завдання, проте, на цьому етапі всі вони, за вийнятком зсуву ${\gamma}$, не мають вхідних параметрів. Після подачі на вхід першого навчального прикладу у вхідній шар додається перший нейрон, центр функції активації \eqref{eq:x_j} якого встановлено наступним чином:

\begin{equation}\label{eq:vec_c_i}
\vec{c_i}=\vec{X},
\end{equation}
\medskip

де $k$ -- номер прикладу у виборці.

Вихідний сигнал першого шару автоматично передається на всі нейрони другого шару, а його лінійні синапси налаштовуються таким чином, щоб різниця між виходом мережі і навчальним сигналом була мінімальна:

\begin{equation}
\vec{w_j}^{[\circ]}=\vec{Y}-\vec{y},
\end{equation}
\medskip

де $\vec{Y}$ -- бажаний вихід мережі.

Доданий нейрон реагуватиме на нові вхідні сигнали, якщо вони будуть перебувати в певному інтервалі, який визначаються відстаню між найближчим вектором і новим вхідним образом

\begin{equation}
w_i=\omega\left\|\vec{X}-\vec{c}_{nearest}\right\|,
\end{equation}
\medskip

де $\omega$ -- параметр покриття, підібраний емпіричним шляхом. Чим більше значення цього параметра, тим на більшу кількість вхідних сигналів будуть реагувати вже існуючі нейрони першого шару.

У RAN використовуються дві умови для додавання нового нейрона в перший шар мережі. По-перше, це відбувається в тому випадку, якщо вхідний сигнал знаходиться далеко від вже існуючих центрів функцій активації нейронів першого шару:

\begin{equation}\label{eq:introActivFuncFirstLayer}
\left\|\vec{X}-\vec{c}_{nearest}\right\|>\delta{(t)},
\end{equation}
\medskip

а також у випадку, коли із допомогою поточного набору елементів не вдається забезпечити необхідну точніть вихідного сигналу:

\begin{equation}\label{eq:introActivFuncOutputSignal}
\left\|\vec{Y}-\vec{y}{(\vec{X})}\right\|>\varepsilon,
\end{equation}
\medskip

де $\varepsilon$ -- необхідна точність вихідного сигналу.

Якщо при подачі на вхід нового вектора на виході мережі ми отримуємо помилку більшу, ніж $\varepsilon$, то у вхідний шар мережі додається новий нейрон з центрами активаційних функцій, налаштованими на поточний вхідний образ.
Відстань $\delta{(k)}$ -- динамічний параметр, який змінює своє значення протягом процесу навчання. Для його калькуляції використовується наступний вираз:

\begin{equation}
\delta(k)=max\left({\delta_{max}e^{-i/{\tau}},\delta_{min}}\right),
\end{equation}
\medskip

де $\delta_{max}$, $\delta_{min}$, $\tau$ -- параметри, що вибираються емпірічно.

Якщо згідно умов  \eqref{eq:introActivFuncFirstLayer} і \eqref{eq:introActivFuncOutputSignal} не потребується додавання нового нейрона у вхідний шар, то проводиться налаштування вагових коефіцієнтів вихідного шару. Для цього можуть використовуватися градієнтні методи мінімізації або ж метод найменших квадратів.
 
На перших етапах навчання в мережу переважно додаються нові елементи, проте через деякий час цей процес сповільнюється і замість додавання нових нейронів у вхідному шар відбувається налаштування синаптичних вагових коефіцієнтів вихідного шару. Такий порядок роботи конструктивного алгоритму стає можливим завдяки використанню двох умов додавання нового нейрона \eqref{eq:introActivFuncFirstLayer} та \eqref{eq:introActivFuncOutputSignal}, забезпечує оптимальну складність моделі нейронної мережі поряд з хорошим рівнем узагальнюючих здібностей. У разі використання виключно \eqref{eq:introActivFuncFirstLayer} найбільш ймовірно, що це призведе до перенавчання, а в разі -- \eqref{eq:introActivFuncOutputSignal} можуть бути пропущені деякі нейрони вхідного шару, що вплине на точність вихідного сигналу мережі.

Серед недоліків запропонованого Джоном Платтом методу має сенс назвати досить велику кількість параметрів, що підбираються емпірично, від яких безпосередньо залежить якість роботи RAN.

Надалі підхід до конструктивної організації архітектури нейронної мережі, відомий в англомовній літературі під назвою Resource Allocation, породив безліч різних модифікацій, які спрямовані на оптимізацію швидкості навчання і точності вихідного сигналу при вирішенні певного кола завдань \hl{[41-44]}.

В рамках конструктивного підходу можна виділити такий напрямок, як каскадні нейронні мережі \hl{[45-50]}, найбільш характерним і ефективним представником яких є каскадно-кореляційний архітектура, запропонована Фальманом і Лєб'єром в роботі \hl{[45]}. Основна особливість мережі цього типу полягає в можливості додавання нових вузлів у процесі навчання. На рис.~\ref{fig:CasCorLA} наведена схема подібної мережі, що містить два каскади.

\begin{figure}[th]
\begin{center}
\includegraphics[width=16cm]{CasCorLA.eps}
\caption{Архітектура каскадної системи (за Фальманом та Лєб'єром) після додавання двох прихованих вузлів. Вхідні сигнали, що надходять до вертикальних ліній, сумуються; вагові коефіцієнти, позначені $\medsquare$, -- зафіксовані, позначeні $\filledmedsquare$, -- налаштовуються}
\label{fig:CasCorLA}
\end{center}
\end{figure}

На початку процесу навчання формується стандартна одношарова структура з декількома входами і єдиним виходом, яка навчається за допомогою того чи іншого нелінійного методу навчання. Після прохождення всієї навчальної вибірки $x\left(1\right), x\left(2\right),\dots, x\left(N\right)$ оцінюється точність апроксимації і в тому випадку, якщо помилка занадто велика, формується каскад з $n_2$ нейронів-кандидатів, паралельно підключених до входів мережі $1, x_1 ,x_2, \dots, x_n$ і виходу першого каскаду $o^{[1]}$. Нейрони-кандидати, як правило, відрізняються один від одного початковими значеннями синаптичних вагових коефіцієнтів $W^{[2]}(0)$, видом функцій активації та алгоритмами навчання. На наступному етапі проводиться навчання нейронів другого каскаду при <<заморожених>> синаптичних коефіцієнтах $W^{[1]}(N)$ першого каскаду. Серед $n_2$ нейронів-кандидатів вибирається один нейрон-переможець, параметр кореляції якого~\hl{[46]}

\begin{equation}
R^2_{[q]}=\left|\sum^{N}\limits_{k=1}\left(o^{[2]}_q\left(k\right)-\bar{o}_q^{[2]}\right)\left(e^{[2]}_q\left(k\right)-\bar{e}_q^{[2]}\right)\right|,\text{ } q=1,2,\dots,n_2
\end{equation}
\medskip

(тут $\bar{o}_q^{[2]}$ і $\bar{e}_q^{[2]}$ - середні значення вихідного сигналу і помилки) є максимальним. Саме цей нейрон з <<замороженими>> вагами $W^{[2]}(N)$ утворює другий каскад, в той час як нейрони, які програли, видаляються з мережі.

Далі оцінюється точність апроксимації, що забезпечується другим каскадом, і в разі потреби формується набір з $n_3$ кандидатів третього каскаду, серед яких вибирається переможець з максимальним значенням

\begin{equation}
R^3_{[q]}=\left|\sum^{N}\limits_{k=1}\left(o^{[3]}_q\left(k\right)-\bar{o}_q^{[3]}\right)\left(e^{[3]}_q\left(k\right)-\bar{e}_q^{[3]}\right)\right|,\text{ } q=1,2,\dots,n_3
\end{equation}
\medskip
У разі досягнення необхідної точності процес нарощування каскадів завершується і вихідний сигнал останнього каскаду (на рис. 1.1 -- $\bar{o}_q^{[3]}$) приймається в якості вихідного сигналу мережі в цілому.
В якості основних відмінних рис каскадно-кореляційних мереж слід зазначити наступні:
\begin{itemize}
\item ці мережі не вимагають попереднього завдання ні архітектури, ні кількості нейронів в каскадах,
\item нейрони в мережу додаються в міру необхідності, утворюючи не приховати шари, а каскади, кожен з яких в якості вхідних сигналів використовує входи мережі і виходи попереднього каскаду,
\item навчання не пов'язане з концепцією зворотнього поширення помилок, що дозволяє істотно скоротити час налаштування
\item за рахунок <<заморожування>> синаптичних ваг сформованих раніше каскадів скорочуються обчислювальні витрати на навчання.
\end{itemize}

Головним недоліком даних мереж прийнято вважати неможливість їх навчання в режимі послідовної обробки інформації \hl{[51]}. Далі буде показано, як можна подолати це обмеження, синтезувавши на основі мережі, запропонованої в \hl{[45]}, архітектуру, яка буде відповідати критеріям, які висуваються до нейро-фаззі систем.

\section{Постановка завдання дослідження}

Оскільки сучасні обчислювальні технології дозволяють накопичувати і обробляти досить великі масиви інформації, то на перший план виходить швидкість обробляння даних, а також можливість роботи з ними в послідовному режимі. Крім того варто зазначити, що інформація, яка обробляється, може характеризуватися нелінійним і нестаціонарним характером даних. У таких випадках доцільно використання штучних нейронних мереж, які володіють універсальними апроксимуючими властивостями. Застосування апарату нечіткої логіки дозволяє розширити функціональні можливості штучних нейронних мереж і коло вирішуваних завдань. Завдання дослідження полягає в розробці архітектур нейро-фаззі мереж і методів їх навчання, що володіють високою гнучкістю налаштування параметрів для інтелектуального аналізу даних в умовах невизначеності. Для досягнення поставленої мети необхідно розглянути наступні питання:

\begin{enumerate}
\item Аналіз існуючих нейро-фаззі архітектур і методів їх навчання.
\item Розробка спеціалізованих штучних нейронів, які мають підвищену (порівняно з традиційними нейронами) швидкістю навчання, а також здатних ефективно вирішувати завдання прогнозування, ідентифікації і класетрування в умовах апріорної і поточної невизначеності.
\item Розробка на основі цих нейронів штучних нейронних мереж зі зростаючою архітектурою та методів їх навчання.
\item Дослідження методів і способів, що дозволяють виконати гібридизацію (перехід від нейро до нейро-нечіткої системи).
\item Розробка методів навчання, що дозволяють гібридній нейро-нечіткій зростаючій архітектурі функціонувати в режимі послідовного обробляння інформації.
\item Проведення імітаційного моделювання розроблених методів і архітектур та розв'язання з їх допомогою практичних завдань.
\end{enumerate}

\section*{Висновки до розділу~\ref{ch:ProbleAnalysis}}

\begin{enumerate}
\item Розглянуто гібридні нейро-фаззі системи для вирішення завдань обробляння інформації за умови апріорної і поточної невизначеності. У якості головного недоліку таких систем виділено відсутність ефективних способів настройки архітектури з можливістю функціонувати в режимі реального часу.
\item Проаналізовано стан проблеми кластерування даних і розглянуті існуючі підходи до її вирішення. Розглянуто основні принципи нечіткої логіки та систем нечіткого висновування. Проаналізовані існуючі архітектури штучних нейронних мереж і методи їх самонавчання, що використовуються для вирішення завдань кластерування даних.
\item Проведено аналіз існуючих конструктивних і деструктивних методів структурної адаптації нейронних мереж. Виділено їх сильні і слабкі сторони. Обґрунтовано доцільність використання конструктивних алгоритмів для синтезу систем, що мають функціонувати в режимі послідовного обробляння даних.
\item Сформульовано завдання дослідження.
\end{enumerate}
\bibliographystyle{ugost2008ns}
\bibliography{references}	
\end{document}
